{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoviZO1YqtAs4NPqNXQ/0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KdimAlex/Sentiment-Classification-Project/blob/master/Make_Inputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download model that contains token vectors that the tokens map to:\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "SfbbSU4UmC1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac91279-8f01-4971-a0f5-1dc317d0cf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-01 20:01:03.330349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-01 20:01:03.330419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-01 20:01:03.330464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-01 20:01:03.343671: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-01 20:01:05.611754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Load the spaCy model with GloVe embeddings\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def get_tok_embedding(paragraph):\n",
        "  tokens = word_tokenize(paragraph)\n",
        "  tok_embeddings = [nlp(token).vector for token in tokens]\n",
        "  return tok_embeddings"
      ],
      "metadata": {
        "id": "i0M6TdHmf--k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925b0034-c53e-4bde-dcea-73d26b4ee7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_pos_embedding (paragraph):\n",
        "  tokens = word_tokenize(paragraph)\n",
        "  position = np.arange(len(tokens))[:, np.newaxis]\n",
        "  div_term = np.exp(np.arange(0, 300, 2) * -(np.log(10000.0) / 300))\n",
        "  pos_embeddings = np.zeros((len(tokens), 300))\n",
        "  pos_embeddings[:, 0::2] = np.sin(position * div_term)\n",
        "  pos_embeddings[:, 1::2] = np.cos(position * div_term)\n",
        "  return pos_embeddings"
      ],
      "metadata": {
        "id": "6OJMIPUegAwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEMPORARY METHOD TO JUST COMPILE FOR SAM TO FIX\n",
        "def get_seg_embedding (paragraph):\n",
        "  tokens = word_tokenize(paragraph)\n",
        "  seg_embeddings = np.ones((len(tokens), 300))\n",
        "  return seg_embeddings"
      ],
      "metadata": {
        "id": "x8fF708ggA3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_embedding (tok_embeddings, pos_embeddings, seg_embeddings):\n",
        "  # Ensure that all the embeddings have the same shape\n",
        "  assert len(tok_embeddings) == len(pos_embeddings) == len(seg_embeddings), \"All embeddings must have the same length\"\n",
        "  # Convert token embeddings list to numpy array if it's not already\n",
        "  if isinstance(tok_embeddings, list):\n",
        "      tok_embeddings = np.array(tok_embeddings)\n",
        "  # Sum the embeddings element-wise\n",
        "  pre_self_attention_embeddings = tok_embeddings + pos_embeddings + seg_embeddings\n",
        "  return pre_self_attention_embeddings"
      ],
      "metadata": {
        "id": "5WQnwGnXd0h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        "    d_k = query.shape[1]  # dimensionality of the key\n",
        "    scores = np.matmul(query, key.T) / np.sqrt(d_k)\n",
        "    weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n",
        "    return np.matmul(weights, value), weights\n",
        "\n",
        "def get_self_attention_embeddings(embeddings, d_model=300):\n",
        "    # Initialize weights for the self-attention layers\n",
        "    # For simplicity, these are random. In practice, they would be learned parameters.\n",
        "    W_q = np.random.rand(d_model, d_model)\n",
        "    W_k = np.random.rand(d_model, d_model)\n",
        "    W_v = np.random.rand(d_model, d_model)\n",
        "\n",
        "    # Calculate query, key, value matrices\n",
        "    query = np.matmul(embeddings, W_q)\n",
        "    key = np.matmul(embeddings, W_k)\n",
        "    value = np.matmul(embeddings, W_v)\n",
        "\n",
        "    # Compute scaled dot-product attention\n",
        "    attention_output, _ = scaled_dot_product_attention(query, key, value)\n",
        "\n",
        "    return attention_output"
      ],
      "metadata": {
        "id": "-PYqW9vSfyOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"My name is Tom, and I am unbelievably hungry.\"\n",
        "\n",
        "token_embeddings = get_tok_embedding (paragraph)\n",
        "position_embeddings = get_pos_embedding (paragraph)\n",
        "segment_embeddings = get_seg_embedding (paragraph)\n",
        "final_embedding = get_final_embedding (token_embeddings, position_embeddings, segment_embeddings)\n",
        "\n",
        "transformer_input = get_self_attention_embeddings(final_embedding)"
      ],
      "metadata": {
        "id": "VPV9czEFgabi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b21474-fbf8-4898-df42-7ae8fad288aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-ccc21ca15832>:4: RuntimeWarning: overflow encountered in exp\n",
            "  weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n",
            "<ipython-input-37-ccc21ca15832>:4: RuntimeWarning: invalid value encountered in divide\n",
            "  weights = np.exp(scores) / np.sum(np.exp(scores), axis=-1, keepdims=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tester for while I am coding:\n",
        "def print_embeddings(tokens, embeddings, embedding_type, num_values=10, decimal_places=4):\n",
        "    for token, embedding in zip(tokens, embeddings):\n",
        "        limited_embedding = embedding[:num_values]\n",
        "        formatted_embedding = [round(value, decimal_places) for value in limited_embedding]\n",
        "        print(f\"{embedding_type} for Token: {token}\")\n",
        "        print(f\"{embedding_type} Embedding (first {num_values} values of {len(embedding)} values): {formatted_embedding}\\n\")\n",
        "\n",
        "tokens = word_tokenize(paragraph)\n",
        "print_embeddings(tokens, token_embeddings, \"Token\")\n",
        "print_embeddings(tokens, position_embeddings, \"Position\")\n",
        "print_embeddings(tokens, segment_embeddings, \"Segment\")\n",
        "print_embeddings(tokens, final_embedding, \"Summed Final\")\n"
      ],
      "metadata": {
        "id": "FCiBA6EikrfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e983fd9d-9971-4719-c39f-e09bf1a417fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token for Token: My\n",
            "Token Embedding (first 10 values of 300 values): [7.6432, 1.5701, -11.373, -7.1437, 3.5173, 1.6061, 1.5734, -0.1969, -3.7184, 5.7551]\n",
            "\n",
            "Token for Token: name\n",
            "Token Embedding (first 10 values of 300 values): [0.9176, -0.7391, 8.3935, -3.5195, 7.3546, -1.2438, 1.3083, -5.036, 2.619, 0.1279]\n",
            "\n",
            "Token for Token: is\n",
            "Token Embedding (first 10 values of 300 values): [1.475, 6.0078, 1.1205, -3.5874, 3.7638, 3.1987, -2.206, 3.2128, -2.0816, -0.0029]\n",
            "\n",
            "Token for Token: Tom\n",
            "Token Embedding (first 10 values of 300 values): [-2.8594, -1.1686, 0.1836, -5.2091, 0.6395, 4.5149, 3.3691, -0.0328, -1.1249, -0.5381]\n",
            "\n",
            "Token for Token: ,\n",
            "Token Embedding (first 10 values of 300 values): [-3.3899, -4.7034, -0.561, 1.2291, 4.3298, -1.0775, -1.3006, 8.7939, -0.1667, -4.3738]\n",
            "\n",
            "Token for Token: and\n",
            "Token Embedding (first 10 values of 300 values): [-3.3477, -6.0854, -3.6366, 0.5348, 8.4195, 1.3784, 0.3117, 5.6086, -0.7768, -3.3725]\n",
            "\n",
            "Token for Token: I\n",
            "Token Embedding (first 10 values of 300 values): [-1.8607, 0.158, -4.1425, -8.6359, -16.955, 1.157, -1.588, 5.6609, -12.03, 16.417]\n",
            "\n",
            "Token for Token: am\n",
            "Token Embedding (first 10 values of 300 values): [8.3869, -7.2075, 2.3706, -11.738, -11.974, 5.3761, -9.966, 11.431, -7.5086, 8.4296]\n",
            "\n",
            "Token for Token: unbelievably\n",
            "Token Embedding (first 10 values of 300 values): [0.3229, -0.0049, -2.1791, -1.9556, 1.299, 1.2768, -0.385, 3.237, -2.1399, -0.8807]\n",
            "\n",
            "Token for Token: hungry\n",
            "Token Embedding (first 10 values of 300 values): [0.56, 0.771, -2.9771, -1.6693, -2.0364, 0.2264, 1.8792, 1.5919, -1.6783, 0.9217]\n",
            "\n",
            "Token for Token: .\n",
            "Token Embedding (first 10 values of 300 values): [-0.0765, -4.6896, -4.0431, -3.4333, 11.758, 3.7212, -0.9813, 2.7902, 0.4361, -2.4425]\n",
            "\n",
            "Position for Token: My\n",
            "Position Embedding (first 10 values of 300 values): [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
            "\n",
            "Position for Token: name\n",
            "Position Embedding (first 10 values of 300 values): [0.8415, 0.5403, 0.8078, 0.5894, 0.7736, 0.6337, 0.7391, 0.6736, 0.7049, 0.7093]\n",
            "\n",
            "Position for Token: is\n",
            "Position Embedding (first 10 values of 300 values): [0.9093, -0.4161, 0.9523, -0.3051, 0.9804, -0.1968, 0.9957, -0.0926, 1.0, 0.0063]\n",
            "\n",
            "Position for Token: Tom\n",
            "Position Embedding (first 10 values of 300 values): [0.1411, -0.99, 0.3148, -0.9492, 0.4691, -0.8831, 0.6022, -0.7983, 0.7138, -0.7003]\n",
            "\n",
            "Position for Token: ,\n",
            "Position Embedding (first 10 values of 300 values): [-0.7568, -0.6536, -0.5812, -0.8138, -0.3859, -0.9226, -0.1844, -0.9829, 0.0127, -0.9999]\n",
            "\n",
            "Position for Token: and\n",
            "Position Embedding (first 10 values of 300 values): [-0.9589, 0.2837, -0.9999, -0.0102, -0.9582, -0.2861, -0.8507, -0.5257, -0.6958, -0.7182]\n",
            "\n",
            "Position for Token: I\n",
            "Position Embedding (first 10 values of 300 values): [-0.2794, 0.9602, -0.5976, 0.8018, -0.8286, 0.5599, -0.9616, 0.2746, -0.9998, -0.019]\n",
            "\n",
            "Position for Token: am\n",
            "Position Embedding (first 10 values of 300 values): [0.657, 0.7539, 0.2955, 0.9554, -0.092, 0.9958, -0.4447, 0.8957, -0.7226, 0.6912]\n",
            "\n",
            "Position for Token: unbelievably\n",
            "Position Embedding (first 10 values of 300 values): [0.9894, -0.1455, 0.9459, 0.3244, 0.712, 0.7022, 0.3625, 0.932, -0.0254, 0.9997]\n",
            "\n",
            "Position for Token: hungry\n",
            "Position Embedding (first 10 values of 300 values): [0.4121, -0.9111, 0.8196, -0.5729, 0.9944, -0.1057, 0.933, 0.3599, 0.6866, 0.727]\n",
            "\n",
            "Position for Token: .\n",
            "Position Embedding (first 10 values of 300 values): [-0.544, -0.8391, 0.0203, -0.9998, 0.5484, -0.8362, 0.8944, -0.4472, 0.9995, 0.0317]\n",
            "\n",
            "Segment for Token: My\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: name\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: is\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: Tom\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: ,\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: and\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: I\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: am\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: unbelievably\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: hungry\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Segment for Token: .\n",
            "Segment Embedding (first 10 values of 300 values): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Summed Final for Token: My\n",
            "Summed Final Embedding (first 10 values of 300 values): [8.6432, 3.5701, -10.373, -5.1437, 4.5173, 3.6061, 2.5734, 1.8031, -2.7184, 7.7551]\n",
            "\n",
            "Summed Final for Token: name\n",
            "Summed Final Embedding (first 10 values of 300 values): [2.7591, 0.8012, 10.2013, -1.9301, 9.1282, 0.3899, 3.0474, -3.3624, 4.3239, 1.8372]\n",
            "\n",
            "Summed Final for Token: is\n",
            "Summed Final Embedding (first 10 values of 300 values): [3.3843, 6.5917, 3.0728, -2.8925, 5.7442, 4.0019, -0.2103, 4.1202, -0.0816, 1.0034]\n",
            "\n",
            "Summed Final for Token: Tom\n",
            "Summed Final Embedding (first 10 values of 300 values): [-1.7183, -1.1586, 1.4984, -5.1583, 2.1086, 4.6318, 4.9713, 0.1688, 0.5889, -0.2384]\n",
            "\n",
            "Summed Final for Token: ,\n",
            "Summed Final Embedding (first 10 values of 300 values): [-3.1467, -4.357, -0.1422, 1.4153, 4.9439, -1.0001, -0.485, 8.811, 0.846, -4.3737]\n",
            "\n",
            "Summed Final for Token: and\n",
            "Summed Final Embedding (first 10 values of 300 values): [-3.3066, -4.8017, -3.6365, 1.5246, 8.4613, 2.0922, 0.461, 6.0829, -0.4727, -3.0907]\n",
            "\n",
            "Summed Final for Token: I\n",
            "Summed Final Embedding (first 10 values of 300 values): [-1.1401, 2.1182, -3.7401, -6.8341, -16.7836, 2.7169, -1.5496, 6.9355, -12.0298, 17.398]\n",
            "\n",
            "Summed Final for Token: am\n",
            "Summed Final Embedding (first 10 values of 300 values): [10.0439, -5.4536, 3.6661, -9.7826, -11.066, 7.3719, -9.4107, 13.3267, -7.2312, 10.1208]\n",
            "\n",
            "Summed Final for Token: unbelievably\n",
            "Summed Final Embedding (first 10 values of 300 values): [2.3123, 0.8496, -0.2332, -0.6312, 3.011, 2.979, 0.9774, 5.169, -1.1653, 1.119]\n",
            "\n",
            "Summed Final for Token: hungry\n",
            "Summed Final Embedding (first 10 values of 300 values): [1.9721, 0.8599, -1.1575, -1.2422, -0.042, 1.1206, 3.8122, 2.9518, 0.0083, 2.6487]\n",
            "\n",
            "Summed Final for Token: .\n",
            "Summed Final Embedding (first 10 values of 300 values): [0.3795, -4.5287, -3.0228, -3.4331, 13.3064, 3.885, 0.9131, 3.343, 2.4356, -1.4108]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}